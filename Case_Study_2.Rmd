---
title: "Case Study 2"
author: "Michael Daniel Bigler and Liam Arthur Phan"
date: "`r Sys.Date()`"
output:
  rmdformats::downcute:
    code_folding: hide
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	include = TRUE,
	fig.align = "center")
rm(list = ls())
cat("\014")

```

<break>

> Goal:

# Packages

> In the following all the packages needed for this case study are loaded.

```{r packages}

library(ggplot2)
library(DT)
library(jtools)
library(kableExtra)
library(pastecs)
library(rcompanion)   #Histogram and Normal Curve
library(nortest) #Kolmogorov-Smirnov-Test
library(corrplot) #correlation matrix plot
library(olsrr)  #VIF and Tolerance Values
library(dplyr)
library(pastecs)
library(REdaS) #Bartelett's Test
library(psych)
library(lm.beta)
library(RColorBrewer)
library(tidyverse)

```

# Data

> . The source is thereby listed below.

> Source: **Advanced Data Driven Decision Making** [S401024](https://moodle.unige.ch/course/view.php?id=2675 "2675") - University of Geneva (GSEM)
>
> Marcel Paulssen, Professor\
> Fereshteh Vahidi, Teaching Assistant\
> Anastasia Floru, Teaching Assistant

```{r data loading}
Mydata <- read.csv("DATA/Data File_Case_Study_Factor Analysis_MD.csv", header=TRUE)

# selecting questions
Mydata_with_y <- Mydata[,c(9:41, 43:45, 51:52)]
Mydata_with_y <- na.omit(Mydata_with_y)
Mydata_qd <- Mydata_with_y[,1:33]
rm(Mydata)
```

## Data Analysis

```{r}
list_na =colnames(Mydata_with_y)[apply(Mydata_with_y,2,anyNA)]
list_na
```

## Data Statistics Summary

```{r}

Stat_Desc <- stat.desc(Mydata_with_y, norm=TRUE)

DT::datatable(round(Stat_Desc,3))

```


# 1. Orthogonal Factor Analysis

## 1.1 Normality Test on All Variables

```{r}

apply(Mydata_with_y[1:33],2,shapiro.test)

```

## 1.1 Correlation Plot

```{r}

cor_mat <- cor(Mydata_with_y)
corrplot(as.matrix(cor_mat), type="upper", order="hclust", tl.col="black", tl.srt=45,tl.cex = 0.5)

```

## 1.2 Anti-image correlation, Kaiser-Meyer-Olkin and Bartlett's test

### Anti-image Correlation

```{r}
KMOTEST=KMOS(Mydata_qd)
sort(KMOTEST$MSA)
```

All values are above 0.6 so a good factor analysis can be done. Only one value is close to not being good enough which is qd4. All the others are over 0.9.

### Bartlett's test

```{r}
bart_spher(Mydata_qd)
```

There is a correlation between variables, and the assumptions are not met since we have above 5 variables 

### Kaiser-Meyer-Olkin

```{r}
KMOTEST=KMOS(Mydata_qd)
KMOTEST$KMO
```

The Kaiser-Meyer-Olkin criterion suggest that the adequacy of the data is marvelous (>0.9). 

## 1.3 Principal axes factoring with varimax

As we know from literature that there are 9 factors we do a factor analysis with 9. 

```{r}
fa_result <- fa(Mydata_qd, rotate = "varimax", fm = "pa")

plot(fa_result$e.values,xlab="Factor Number",ylab="Eigenvalue",main="Scree plot",cex.lab=1.2,cex.axis=1.2,cex.main=1.8)+abline(h=1)

factors_kaiser <- sum(fa_result$e.values>1)
```

Kaiser criterion gives `r factors_kaiser` factors, scree-test gives 10. From literature we know that there should be 9 factors. We first do a factor analysis with 8 factors to see if it makes sense. 

```{r}
fa_result_8 <- fa(Mydata_qd, rotate = "varimax", fm = "pa", nfactors = 8)
print(fa_result_8$loadings, cutoff=0.3,sort=TRUE)
```

We see that every question is loaded in a factor except for the question 4 and 23. We get similar results when we look at the communalities. 

```{r}
FA_communalities_8=data.frame(sort(fa_result_8$communality))
problematic_communalities_8 <- rownames(FA_communalities_8)[FA_communalities_8<0.5]
problematic_communalities_8
```

We see that there are two communalities which are below 0.5. They are fittingly for qd4 and qd23. 

As by literature there are 9 factors we rerun the factor analysis to see the loadings for 9 factors. 

```{r}
fa_result_9 <- fa(Mydata_qd, rotate = "varimax", fm = "pa", nfactors = 9)
print(fa_result_9$loadings, cutoff=0.3,sort=TRUE)
```

We can observe that the loadings for factor 9 are solely based on question 4 and question 23. We rerun the communalities

```{r}
FA_communalities_9=data.frame(sort(fa_result_9$communality))
problematic_communalities_9 <- rownames(FA_communalities_9)[FA_communalities_9<0.5]
problematic_communalities_9
```

Again we see that thetige.  question 4 and 23 are problematic. To see if we should exclude them we look at the questionnaire. Both question related to prestige therefore we leave them in and factor 9 is prestige. 

## 1.4 Final Factor Solutions

```{r}

Aesthetics_Appearance <- Mydata_with_y[c("qd1","qd10","qd20","qd27")]
Durability <- Mydata_with_y[c("qd26","qd28","qd31")]
Ease_of_Use <- Mydata_with_y[c("qd3","qd11","qd13","qd30")]
Features_Versatility <- Mydata_with_y[c("qd6","qd8","qd18","qd25")]
Conformance <- Mydata_with_y[c("qd15","qd17","qd32")]
Performance <- Mydata_with_y[c("qd2","qd5","qd7","qd12","qd16")]
Reliability_Flawlessness <- Mydata_with_y[c("qd22","qd29","qd33")]
Serviceability <- Mydata_with_y[c("qd9","qd14","qd19","qd21","qd24")]
Distinctiveness_Prestige <- Mydata_with_y[c("qd4","qd23")]

All_Factors <- cbind(Aesthetics_Appearance,Durability,Ease_of_Use,Features_Versatility,Conformance,Performance,Reliability_Flawlessness,Serviceability,Distinctiveness_Prestige)

DT::datatable(Aesthetics_Appearance, caption = "Aesthetics & Appearance")
DT::datatable(Durability,caption = "Durability" )
DT::datatable(Ease_of_Use,caption = "Ease of Use")
DT::datatable(Features_Versatility,caption = "Features & Versatility")
DT::datatable(Conformance,caption = "Conformance")
DT::datatable(Performance,caption = "Performance")
DT::datatable(Reliability_Flawlessness,caption = "Reliability & Flawlessness")
DT::datatable(Serviceability,caption = "Serviceability")
DT::datatable(Distinctiveness_Prestige,caption = "Distinctiveness & Prestige")

DT::datatable(All_Factors, caption = "All Factors")

```




